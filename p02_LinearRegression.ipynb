{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Doc: https://jovian.ml/aakashns/02-linear-regression\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "inputs = torch.from_numpy(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')\n",
    "targets = torch.from_numpy(targets)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Linear Regression**\n",
    "\n",
    "    yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "    yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3716, -1.0864, -0.0716],\n",
      "        [ 1.7949, -1.0946, -0.3089]], requires_grad=True)\n",
      "tensor([0.7005, 0.2067], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True) # 2 outputs and 3 features\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model in Matrix Notation\n",
    ">### X * W<sup>T</sup> + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "def reg_model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-102.2943,   44.6157],\n",
       "        [-133.3009,   47.4516],\n",
       "        [-181.3603,   -8.2244],\n",
       "        [ -86.5678,  124.7891],\n",
       "        [-134.2460,   -2.6449]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Predictions based on random initialisation of weights\n",
    "preds = reg_model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "# def mse(t1, t2):\n",
    "#     diff = t1 - t2\n",
    "#     return torch.sum(diff * diff) / diff.numel() # numel returns number of tensor\n",
    "\n",
    "# MSE loss: Alterate implementation\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.mean(diff**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27523.1465, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss  = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3716, -1.0864, -0.0716],\n",
      "        [ 1.7949, -1.0946, -0.3089]], requires_grad=True)\n",
      "tensor([[-16926.4219, -19431.3027, -11713.4082],\n",
      "        [ -3690.2998,  -6648.0132,  -3595.3179]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Before we proceed, we reset the gradients to zero by calling .zero_() method. \n",
    "# We need to do this, because PyTorch accumulates, gradients i.e. \n",
    "# the next time we call .backward on the loss, \n",
    "# the new gradient values will get added to the existing gradient values, \n",
    "# which may lead to unexpected results\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust weights and biases using gradient descent\n",
    "\n",
    "We'll reduce the loss and improve our model using the gradient descent optimization algorithm, which has the following steps:\n",
    "\n",
    " Generate predictions\n",
    "\n",
    "    Calculate the loss\n",
    "\n",
    "    Compute gradients w.r.t the weights and biases\n",
    "\n",
    "    Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "    Reset the gradients to zero\n",
    "\n",
    "Let's implement the above step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-102.2943,   44.6157],\n",
      "        [-133.3009,   47.4516],\n",
      "        [-181.3603,   -8.2244],\n",
      "        [ -86.5678,  124.7891],\n",
      "        [-134.2460,   -2.6449]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = reg_model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27523.1465, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-16926.4219, -19431.3027, -11713.4082],\n",
      "        [ -3690.2998,  -6648.0132,  -3595.3179]])\n",
      "tensor([-203.7539,  -50.8026])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note above:\n",
    "\n",
    "    We use torch.no_grad to indicate to PyTorch that we shouldn't track, calculate or modify gradients while updating the weights and biases. \n",
    "\n",
    "    We multiply the gradients with a really small number (10^-5 in this case), to ensure that we don't modify the weights by a really large amount, since we only want to take a small step in the downhill direction of the gradient. This number is called the learning rate of the algorithm. \n",
    "\n",
    "    After we have updated the weights, we reset the gradients back to zero, to avoid affecting any future computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2024, -0.8921,  0.0456],\n",
      "        [ 1.8318, -1.0281, -0.2729]], requires_grad=True)\n",
      "tensor([0.7025, 0.2072], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19579.8086, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = reg_model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = reg_model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(932.6644, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate loss\n",
    "preds = reg_model(inputs)\n",
    "loss = mse(preds,targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using PyTorch built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 73.,  67.,  43.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [103., 119.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 56.,  70.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4432,  0.3406, -0.0900],\n",
      "        [-0.0532, -0.3979, -0.2754]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3045, 0.3222], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "reg_model2 = nn.Linear(3, 2)\n",
    "print(reg_model2.weight)\n",
    "print(reg_model2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4432,  0.3406, -0.0900],\n",
       "         [-0.0532, -0.3979, -0.2754]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3045, 0.3222], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "list(reg_model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-13.0981, -42.0692],\n",
       "        [-15.8127, -57.1679],\n",
       "        [  2.1687, -73.6082],\n",
       "        [-33.5863, -32.4102],\n",
       "        [ -3.8769, -60.8324],\n",
       "        [-13.0981, -42.0692],\n",
       "        [-15.8127, -57.1679],\n",
       "        [  2.1687, -73.6082],\n",
       "        [-33.5863, -32.4102],\n",
       "        [ -3.8769, -60.8324],\n",
       "        [-13.0981, -42.0692],\n",
       "        [-15.8127, -57.1679],\n",
       "        [  2.1687, -73.6082],\n",
       "        [-33.5863, -32.4102],\n",
       "        [ -3.8769, -60.8324]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = reg_model2(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15973.0303, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss\n",
    "loss_mod2 = loss_fn(reg_model2(inputs),targets)\n",
    "print(loss_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "# model.parameters() is passed as an argument to optim.SGD, \n",
    "# so that the optimizer knows which matrices should be modified during the update step\n",
    "opt = torch.optim.SGD(reg_model2.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train model\n",
    "# we'll work batches of data, instead of processing the entire training data in every iteration\n",
    "def fit_model(num_epochs, model, loss_fn, optimizer):\n",
    "    # Repeat for given epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train with batch data\n",
    "        for xb, yb in train_dl:\n",
    "            # Generate predictions\n",
    "            pred = reg_model2(xb)\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            # Update parameters using gradients\n",
    "            optimizer.step()\n",
    "            # Reset gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # Print the progress\n",
    "        if (epoch+1) %10 == 0:\n",
    "            # loss.item returns the actual value stored in the loss tensor\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 177.6140\n",
      "Epoch [20/100], Loss: 86.6753\n",
      "Epoch [30/100], Loss: 120.5985\n",
      "Epoch [40/100], Loss: 116.1549\n",
      "Epoch [50/100], Loss: 135.8946\n",
      "Epoch [60/100], Loss: 33.7600\n",
      "Epoch [70/100], Loss: 51.7913\n",
      "Epoch [80/100], Loss: 41.3989\n",
      "Epoch [90/100], Loss: 34.8453\n",
      "Epoch [100/100], Loss: 20.6047\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "fit_model(100, reg_model2, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.1252,  72.3234],\n",
       "        [ 80.0964,  98.3822],\n",
       "        [123.0555, 136.8588],\n",
       "        [ 25.2073,  46.5031],\n",
       "        [ 95.8218, 109.5451],\n",
       "        [ 58.1252,  72.3234],\n",
       "        [ 80.0964,  98.3822],\n",
       "        [123.0555, 136.8588],\n",
       "        [ 25.2073,  46.5031],\n",
       "        [ 95.8218, 109.5451],\n",
       "        [ 58.1252,  72.3234],\n",
       "        [ 80.0964,  98.3822],\n",
       "        [123.0555, 136.8588],\n",
       "        [ 25.2073,  46.5031],\n",
       "        [ 95.8218, 109.5451]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = reg_model2(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
